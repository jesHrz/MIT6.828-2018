# Lab2

## Exercise 1

> Q: In the file `kern/pmap.c`, you must implement code for the following functions (probably in the order given).
>
> ```
> boot_alloc()
> mem_init() (only up to the call to `check_page_free_list(1)`)
> page_init()
> page_alloc()
> page_free()
> ```
>
> `check_page_free_list()` and `check_page_alloc()` test your physical page allocator. You should boot JOS and see whether `check_page_alloc()` reports success. Fix your code so that it passes. You may find it helpful to add your own `assert()`s to verify that your assumptions are correct.

This is an exercise for physical page management. Function `boot_alloc` will allocate space for page directory and page tables. 

```c
static void * boot_alloc(uint32_t n) {
	static char *nextfree;  // virtual address of next byte of free memory
    char *result;

    // Initialize nextfree if this is the first time.
    // 'end' is a magic symbol automatically generated by the linker,
    // which points to the end of the kernel's bss segment:
    // the first virtual address that the linker did *not* assign
    // to any kernel code or global variables.
    if (!nextfree) {
        extern char end[];
        nextfree = ROUNDUP((char *) end, PGSIZE);
    }

    // Allocate a chunk large enough to hold 'n' bytes, then update
    // nextfree.  Make sure nextfree is kept aligned
    // to a multiple of PGSIZE.
    //
    // LAB 2: Your code here.
    void* mem_addr = NULL;
    if(!n) {
        mem_addr = (void*)nextfree;
    } else if(n > 0) {
        mem_addr = (void*)nextfree;
        nextfree = ROUNDUP(nextfree + n, PGSIZE);
        if((PADDR(nextfree) >> PGSHIFT) >= npages) {
            return NULL;
        }
    }
    return mem_a
}
```

`page_init` will initialize all the page table entries and determine whether it is free or in used and then get a linked list of all the free pages.

```c
void page_init(void) {
    // The example code here marks all physical pages as free.
    // However this is not truly the case.  What memory is free?
    //  1) Mark physical page 0 as in use.
    //     This way we preserve the real-mode IDT and BIOS structures
    //     in case we ever need them.  (Currently we don't, but...)
    //  2) The rest of base memory, [PGSIZE, npages_basemem * PGSIZE)
    //     is free.
    //  3) Then comes the IO hole [IOPHYSMEM, EXTPHYSMEM), which must
    //     never be allocated.
    //  4) Then extended memory [EXTPHYSMEM, ...).
    //     Some of it is in use, some is free. Where is the kernel
    //     in physical memory?  Which pages are already in use for
    //     page tables and other data structures?
    //
    // Change the code to reflect this.
    // NB: DO NOT actually touch the physical memory corresponding to
    // free pages!
    size_t i;
    size_t io_start_page = IOPHYSMEM / PGSIZE;
    size_t kern_end_page = PADDR(boot_alloc(0)) / PGSIZE;
    page_free_list = NULL;
    for (i = 0; i < npages; i++) {
        if(i == 0) {
            pages[i].pp_ref = 1;
            pages[i].pp_link = NULL;
        } else if(i < npages_basemem) {
            pages[i].pp_ref = 0;
            pages[i].pp_link = page_free_list;
            page_free_list = &pages[i];
        } else if(io_start_page <= i && i < kern_end_page) {
            pages[i].pp_ref = 1;
            pages[i].pp_link = NULL;
        } else {
            pages[i].pp_ref = 0;
            pages[i].pp_link = page_free_list;
            page_free_list = &pages[i];
        }
    }
}
```

 `page_alloc` will allocate one page and clear it with 0. The difference between `boot_alloc` and `page_alloc` is that `boot_alloc` just allocs for page directory and page tables and it is called for only once, `page_alloc` is called to allocate one page in the future. 

```c
struct PageInfo * page_alloc(int alloc_flags) {
    // Fill this function in
    if(!page_free_list) {
    // warn("page_alloc: no free page to alloc");
        return NULL;
    }
    struct PageInfo* page_to_alloc = page_free_list;
    page_free_list = page_free_list->pp_link;
    page_to_alloc->pp_link = NULL;
    if(alloc_flags & ALLOC_ZERO) {
        memset(page2kva(page_to_alloc), 0, PGSIZE);
    }
    return page_to_alloc;
}
```

Finally, `page_free` will namely free a page.

```c
void page_free(struct PageInfo *pp) {
    // Fill this function in
    // Hint: You may want to panic if pp->pp_ref is nonzero or
    // pp->pp_link is not NULL.
    if(pp->pp_ref) {
        panic("Reference of page at %08x is nonzero!", pp);
    }
    if(pp->pp_link) {
        panic("Free page link of page at %08x is not NULL!", pp);
    }
    pp->pp_link = page_free_list;
    page_free_list = pp;
}
```

What we need to do in function `mem_init` at present is to alloc a space for pages and clear them. The code is simple:

```c
    pages = (struct PageInfo*)boot_alloc(npages * sizeof(struct PageInfo));
    memset(pages, 0, npages * sizeof(struct PageInfo));
```

The link address of JOS kernel is 0xF0000000 so that the physical address would not be greater than 0x10000000 which means the memory limit is 256MB otherwise the linear address can not be expressed in C language. At the begining, the emulator QEMU allocates 320MB for the virtual machine (I do not know why) and thus an overflow in macro `KADDR` occured. Finally I limit the memory to 256MB with argument flag `-m 256M` and pass the  test. Take care of it!

## Exercise 2 & Exercise 3

In this exercise the guide book let us to know something about segmentation, page translation and page-based protection and the concepts of virtual address, linear address and physical address. In brief speaking, the address all we used in our programming language is *Virtual Address*. After the sementation, the *Virtual Address* is translated to *Linear Address*. If the Paging is enabled, the *Linear Address* will be translated to *Physical Address* by Paging again otherwise the *Linear Address* is *Physical Address*. The NorthBridge is connected with CPU and once CPU gives a *Virtual Address* and MMU translates it to *Physical Address*, the NorthBridge will send to the exact memory unit according to the *Physical Address* and thus we get the data.

## Exercise 4

> Q: In the file `kern/pmap.c`, you must implement code for the following functions.
>
> ```
>         pgdir_walk()
>         boot_map_region()
>         page_lookup()
>         page_remove()
>         page_insert()
> ```
>
> `check_page()`, called from `mem_init()`, tests your page table management routines. You should make sure it reports success before proceeding.

This is an exercise about operation on Page Directory and Page Tables.

Function `pgdir_walk` will return the exact page table entry given a virtual address.

- First of all, we need to get the page directory entry according to the page directory index of va using macro`PDX`
- If the page dirctory entry is not Present or the coresponding page table is not exist then we will allocate one page for the page table and update the PDE
- Now we get the page table, we will get the exact page table entry by page table index of va using macro `PTX`

Here is the code:

```c
pte_t *
pgdir_walk(pde_t *pgdir, const void *va, int create)
{
    // Fill this function in
    pgdir += PDX(va);
    if(!(*pgdir & PTE_P)) {
        if(!create) {
            return NULL;
        }
        struct PageInfo* pp;
        if(!(pp = page_alloc(ALLOC_ZERO))) {
            return NULL;
        }
        pp->pp_ref++;
        *pgdir = page2pa(pp) | PTE_P | PTE_U | PTE_W;
    }
    pte_t* ptb = (pte_t*)KADDR(PTE_ADDR(*pgdir));
    pte_t* pte = &ptb[PTX(va)];
    return pte;
}
```

Function `boot_map_region` will map a range of virtual address to the physical address. What we need to do is find all the page table entries and update their BASE field.

Here is the code:

```c
static void
boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
{
    // Fill this function in
    size_t i;
    pte_t* pte;
    for(i = 0; i < size; i += PGSIZE) {
        pte = pgdir_walk(pgdir, (void*)(va + i), 1); // if not exist, create it
        if(pte) {
            *pte = (pa + i) | perm | PTE_P;
        }
    }
}
```

Function `page_lookup` will find the page table entry and coresponding `strct PageInfo` for a given virtual address. We need to find the page table entry using `pgdir_walk`, get its physical address and get the `struct PageInfo` using `pa2page`.

```C
struct PageInfo *
page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
{
    // Fill this function in
    pte_t* pte = pgdir_walk(pgdir, va, 0);
    if(!pte || !(*pte & PTE_P)) {
        // the pte for this page is not exist
        return NULL;
    }
    if(pte_store) {
        *pte_store = pte;
    }
    return pa2page(PTE_ADDR(*pte));

```

Function `page_remove` will unmap the physical page at a given virtual address.

- We need to find the coresponding page table entry and physical page firstly. If the page is not exist or not present, we do nothing.
- We then decrease the reference of the physical page and clear the PTE, finally we invalidate the TLB

```c
void
page_remove(pde_t *pgdir, void *va)
{
    // Fill this function in
    pte_t* pte;
    struct PageInfo* pp = page_lookup(pgdir, va, &pte);
    if(!pp || !(*pte & PTE_P)) {
        return;
    }
    page_decref(pp);
    *pte = 0;
    tlb_invalidate(pgdir, va);
}
```

Function `page_insert` will map the physical page at a given virtual address.

- Firstly we get the page table entry, and if the page table is not exist, allocate one for it.
- Increase the reference of the physical page
- Check whether the page table entry is in used, if so clean it using `page_remove`
- Update the page table entry

```C
int
page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
{
    // Fill this function in
    pte_t* pte = pgdir_walk(pgdir, va, 1);
    if(!pte) {
        return -E_NO_MEM;
    }
    // should increment the `ref` before removing the page
    // because we will decrease the `ref` of the page in page_remove() .
    pp->pp_ref++;
    if(*pte & PTE_P) {
        page_remove(pgdir, va);
    } 
    *pte = page2pa(pp) | perm | PTE_P;
    return 0;
}
```

As we can see, in JOS, there are two-level paging mechainsm, page directory and page tables. Each entry (4 Bytes) of page directory indicates the base of a page table correspondingly and each entry (4 Bytes) of page table idicates the base of a page. For a linear address, the upper 10 bits indicates the index of page directory entry, and the middle 10 bits indicates the index of page table entry, the lower 12 bits is the offset within a page. The whole pages are managed by an array of type `struct PageInfo` with size of 4 Bytes. So the offset in the array indicates the physical page address (known as *Real Page Number*) and we can see some related macros for address transformation in file `kern/pmap.h`.

## Exercise 5

> Q: Fill in the missing code in `mem_init()` after the call to `check_page()`.
>
> Your code should now pass the `check_kern_pgdir()` and `check_page_installed_pgdir()` checks.

There are 3 code missings

- Map 'pages' read-only to the user page space at UPAGES. 

  ```c
  boot_map_region(kern_pgdir, UPAGES, PTSIZE, PADDR(pages), PTE_U | PTE_P);
  ```

- Map kernel stack to the physical stack `bootstack`

  ```c
  boot_map_region(kern_pgdir, KSTACKTOP - KSTKSIZE, KSTKSIZE, PADDR(bootstack) , PTE_W);
  ```

- Map virtual address [KERNBASE, 2^32) to physical address [0, 2^32 - KERNBASE)

  ```c
  boot_map_region(kern_pgdir, KERNBASE, 0xffffffff - KERNBASE + 1, 0, PTE_W);
  ```

> Q: What entries (rows) in the page directory have been filled in at this point? What addresses do they map and where do they point?

![image.png](https://i.loli.net/2020/08/06/KngBiuJ96RY2de8.png)

> Q: We have placed the kernel and user environment in the same address space. Why will user programs not be able to read or write the kernel's memory? What specific mechanisms protect the kernel memory?

We use the USER bit to limit the access of user application. If the USER bit is clear, the page is accessible for kernel only. User's CPL is 3 and only CPL between 0 - 2 can access a page with USER bit. So the kernel memory is protected.

> Q: What is the maximum amount of physical memory that this operating system can support? Why?

2GB. Virtual address `UPAGES` is mapped to `pages` , and the size is `PTSIZE`, 4MB. Since the size of `struct PageInfo` is 8B, we have 4MB/8B=512K pages totally and thus the maximum amount of physical memory we can use is 512K*4KB=2GB.

> Q: How much space overhead is there for managing memory, if we actually had the maximum amount of physical memory? How is this overhead broken down?

We know from the above that there are 512K pages we can use totally, that is to say there are 512K PTES, for one page can store 1K PTES so 512 pages (512*4KB=2MB) are needed to store the whole PTES. In addition one page is needed to store the page directory which cost 4KB. Here we conclude that the space overhead for memory management is 4MB(pages)+2MB(page tables)+4KB(page directory), totally 6MB+4KB.

>Q: Revisit the page table setup in `kern/entry.S` and `kern/entrypgdir.c`. Immediately after we turn on paging, EIP is still a low number (a little over 1MB). At what point do we transition to running at an EIP above KERNBASE? What makes it possible for us to continue executing at a low EIP between when we enable paging and when we begin running at an EIP above KERNBASE? Why is this transition necessary?

In file `kern/entry.S`, we jump to running at a high EIP above `KERNBASE` after the execution of following codes.

```asm
mov $relocated, %eax
jmp *%eax
```

At the begining of the kernel, The page directory we loaded is `entry_pgdir` which map virtual address [0, 4M) and [KERNBASE, KERNBASE + 4) to physical address [0, 4M) so the kernel are running normally. But in function `mem_init()` we load `kern_pgdir` which dose not map the low virtual address [0, 4M) to `cr3` thus it is necessary to jump to a high EIP above `KERNBASE`.

## Challenges

For the chanllengs are a little bit difficult, I just implement the following one chanllenge.

> Extend the JOS kernel monitor with commands to:
>
> - Display in a useful and easy-to-read format all of the physical page mappings (or lack thereof) that apply to a particular range of virtual/linear addresses in the currently active address space. For example, you might enter `'showmappings 0x3000 0x5000'` to display the physical page mappings and corresponding permission bits that apply to the pages at virtual addresses 0x3000, 0x4000, and 0x5000.
> - Explicitly set, clear, or change the permissions of any mapping in the current address space.
> - Dump the contents of a range of memory given either a virtual or physical address range. Be sure the dump code behaves correctly when the range extends across page boundaries!
> - Do anything else that you think might be useful later for debugging the kernel. (There's a good chance it will be!)

Here are the codes:

```c
int
_page_descriptor_info(pte_t* pte) {
    if(!pte || !(*pte & PTE_P)) {
        cprintf("not mapped");
        // cprintf("perm: ----");
        return ~0;
    }
    char perm_U = (*pte & PTE_U) ? 'U' : 'S';
    char *perm_RW = (*pte & PTE_W) ? "RW" : "R-";
    cprintf("pa %08x P%c%s", PTE_ADDR(*pte), perm_U, perm_RW);
    return 0;
}

int
mon_showmappings(int argc, char **argv, struct Trapframe* tf)
{
    if(argc < 2) {
        cprintf("Usage: showmappings <begin_addr> [<end_addr>]\n");
        return 0;
    }  

    uint32_t begin = strtol(argv[1], NULL, 16);
    uint32_t end;
    if(argc > 2) {
        end = strtol(argv[2], NULL, 16);
        if(begin > end) {
            cprintf("error: <begin> should not be greater than <end>\n");
            return 0;
        }
    } else {
        end = begin;
    }
    
    extern pde_t *kern_pgdir;

    uint32_t va;
    pte_t* pte;
    for(va = begin; va <= end; va += PGSIZE) {
        pte = pgdir_walk(kern_pgdir, (void*)va, 0);
        cprintf("va %08x => ", va);
        _page_descriptor_info(pte);
        cprintf("\n");
    }
    return 0;
}

int
mon_setperm(int argc, char **argv, struct Trapframe* tf) 
{
    size_t i;
    int perm;
    char* cmd;

    uint32_t va = (uint32_t)strtol(argv[1], NULL, 16);

    pte_t* pte = pgdir_walk(kern_pgdir, (void*)va, 0);
    if(!pte || !(*pte & PTE_P)) {
        cprintf("va=%08x not mapped\n", va);
        return 0;
    }
    cprintf("before va %08x => ", va);
    if(_page_descriptor_info(pte)) {
        cprintf("\n");
        return ~0;
    }
    cprintf("\n");

    for(i = 2; i < argc; ++i) {
        cmd = argv[i];
        if(cmd[0] == '+') {
            perm = 0;
            if(cmd[1] == 'U' || cmd[1] == 'u') {
                perm = PTE_U;
            } else if (cmd[1] == 'W' || cmd[1] == 'w') {
                perm = PTE_W;
            } else {
                cprintf("invaild permission `%c`\n", cmd[1]);
            }
            *pte |= perm;
        } else if(cmd[0] == '-') {
            perm = 0;
            if(cmd[1] == 'U' || cmd[1] == 'u') {
                perm = PTE_U;
            } else if (cmd[1] == 'W' || cmd[1] == 'w') {
                perm = PTE_W;
            } else {
                cprintf("invaild permission `%c`\n", cmd[1]);
            }
            *pte &= ~perm;
        } else {
            cprintf("invaild operation `%c`\n", cmd[0]);
        }
    }
    cprintf("after va %08x => ", va);
    _page_descriptor_info(pte);
    cprintf("\n");
    return 0;
}

int
mon_vmdump(int argc, char **argv, struct Trapframe* tf)
{
    if(argc < 3) {
        cprintf("Usage: vmdump /<size> 0x<vm_addr> (size in decimal)");
        return 0;
    }

    size_t size = (size_t)strtol(argv[1] + 1, NULL, 10);
    uint32_t* va = (uint32_t*)strtol(argv[2], NULL, 16);

    size_t i;
    pte_t* pte;
    for(i = 0; i < size; ++i) {
        pte = pgdir_walk(kern_pgdir, (void*)(va + i), 0);
        if(!pte || !(*pte & PTE_P)) {
            cprintf("%08x: Cannot access memory\n");
        } else {
            cprintf("%08x: %08x\n", va + i, *(va + i)); 
        }
    }
    return 0;
}
```

# This completes the lab:)
